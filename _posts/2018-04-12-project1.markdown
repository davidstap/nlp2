*Deadline Project 1 02-05-2018*

Dirichlet [notebook](https://github.com/uva-slpl/nlp2/tree/gh-pages/resources/notebooks/Dirichlet.ipynb)


Tips:

If you are using dense arrays and are running out of memory, sort your vocabulary by frequency and discard all but the top K types by mapping the least frequent ones to some symbol e.g. -UNK-, this way you get to reduce your vocabulary size.
If the validation (or test) set contains words that were never seen at training time, there are two solutions:
You can map all words that occurred a single time at training time to a symbol, e.g. -LOW-, then whenever you encounter an unseen word in the future, replace it by that symbol (also note that if you employed strategy 1 above, you already have a solution to this problem, simply map it to -UNK-);
Alternatively, note that word alignment is a fully unsupervised problem, thus we typically do not make a distinction between training/validation/test sets, this time we are doing it, just so you can track AER scores. This amounts to saying that it is not cheating to concatenate the validation set and the training set when inducing your unsupervised alignments. If still that makes you uneasy, then go with the suggestion above.
In IBM2, one can have a special jump event for alignments to NULL, this should lead to some small improvements (in log-likelihood and AER). The intuition is that alignments to NULL may imply very long jumps, collapsing all alignments to NULL reduce sparsity.
Leave out NULL-alignments from your output, since they are not included in the annotated (test) data. You will only get penalized for them.
If your log-likelihoods are different (e.g. lower) than the ones reported here, you might want to check if you are aligning in the right direction. We are assuming that French words are generated by English words, and that the NULL word is therefore on the English side.
