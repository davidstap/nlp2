---
layout: post
title:  Project 3 updated 
date:   2017-05-29
author: Joost
categories: projects
---

Hi everyone,

We've pushed an update to the Project 3 code that adds better initialization and now uses the Adam optimizer. Adam has an adaptive learning rate, and we found it to be much better in optimization than SGD in this case. It will require a bit more memory though.

Please use this version of the code since we also fixed a mistake in the AER calculation. (Sorry!) With the current settings (i.e. a vocabulary of only 1000 types), you will reach a validation AER of about 0.45 after one epoch, and it will not improve much from there. With a larger vocabulary, you should expect a much lower AER of about 0.32, and whatever you try it will be hard to beat  ~0.25.

If you want to know more about Adam, you can read more [here](https://arxiv.org/abs/1412.6980)

Don't wait too long to get started!

Best,

Wilker & Joost

# FAQ

* Where are the manual alignments for the test set?

We have uploaded the alignments, you should be able to find them on github now.

* How do I do model selection?

Just like you did for project 1. That is, you should use *validation* log-likelihood and *validation* AER to track the performance after each epoch. At the end of training, you assess performance on *test set* using the best parameters you've got.

* How do I track log-likelihood of training data?

That's tricky. You don't really want to track the likelihood of the complete training data because that would be rather expensive. One strategy is to plot likelihood of each training mini-batch. Another strategy is to keep a running average for each epoch (that's what Joost implemented for you). 

* How many terms do I need in the Taylor expansion of the KL?

Use something like 5 to 10.

* What if I get numerical problems when computing the KL?

You can constrain your predictions for parameters of Beta and Kuma to be in (0, k] where k is some small positive integer (e.g. 10). For example you can clip your activations to that interval. This is not super satisfactory, but better strategies are considerably more involved. 

* Do I need NULL words on the English side in T3 and T4?

Actually, you don't! The collocation variables mediate between translation and insertion which makes NULL words unnecessary. 

* What if I already did everything with NULL words in T3 and T4?

That's okay. Now you know you didn't have to ;)


